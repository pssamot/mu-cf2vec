{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_vae = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just choose the name of the dataset directory\n",
    "DATA_DIR = '/Users/tomas/Documents/FEUP/Tese/data/ml-20m/processed_70_10_20'\n",
    "if is_vae:\n",
    "    PARSE_DATA_DIR = os.path.join(DATA_DIR, 'embeddings/vae')\n",
    "else:\n",
    "    PARSE_DATA_DIR = os.path.join(DATA_DIR, 'embeddings/cdae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'metadataset_k_20.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>first_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7648</td>\n",
       "      <td>-0.431028</td>\n",
       "      <td>0.273519</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.021366</td>\n",
       "      <td>0.411798</td>\n",
       "      <td>0.445795</td>\n",
       "      <td>1.206461</td>\n",
       "      <td>0.437548</td>\n",
       "      <td>-0.670044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.261934</td>\n",
       "      <td>0.238986</td>\n",
       "      <td>0.150137</td>\n",
       "      <td>-0.024725</td>\n",
       "      <td>-0.349221</td>\n",
       "      <td>3.509393</td>\n",
       "      <td>-0.146421</td>\n",
       "      <td>1.508804</td>\n",
       "      <td>-0.859744</td>\n",
       "      <td>als_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13315</td>\n",
       "      <td>-0.706174</td>\n",
       "      <td>-0.031290</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>-0.097111</td>\n",
       "      <td>0.111871</td>\n",
       "      <td>0.484369</td>\n",
       "      <td>0.737223</td>\n",
       "      <td>-1.132764</td>\n",
       "      <td>1.119018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040254</td>\n",
       "      <td>-1.375516</td>\n",
       "      <td>-0.064951</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>0.757224</td>\n",
       "      <td>0.444452</td>\n",
       "      <td>0.753969</td>\n",
       "      <td>-0.582505</td>\n",
       "      <td>0.761838</td>\n",
       "      <td>bpr_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16144</td>\n",
       "      <td>0.672244</td>\n",
       "      <td>-0.958536</td>\n",
       "      <td>-0.005133</td>\n",
       "      <td>-0.093083</td>\n",
       "      <td>0.118219</td>\n",
       "      <td>-0.325690</td>\n",
       "      <td>1.434977</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>-0.780396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159395</td>\n",
       "      <td>-0.746610</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>-0.813577</td>\n",
       "      <td>1.753534</td>\n",
       "      <td>-0.063353</td>\n",
       "      <td>-0.829087</td>\n",
       "      <td>-1.122440</td>\n",
       "      <td>most_popular_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18064</td>\n",
       "      <td>-0.813108</td>\n",
       "      <td>0.897909</td>\n",
       "      <td>-0.105261</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>0.099298</td>\n",
       "      <td>-1.109625</td>\n",
       "      <td>2.775797</td>\n",
       "      <td>0.139941</td>\n",
       "      <td>-0.745728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584199</td>\n",
       "      <td>0.619601</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.051431</td>\n",
       "      <td>-1.668557</td>\n",
       "      <td>1.609979</td>\n",
       "      <td>-1.117613</td>\n",
       "      <td>1.222671</td>\n",
       "      <td>-2.145877</td>\n",
       "      <td>lmf_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24397</td>\n",
       "      <td>0.891482</td>\n",
       "      <td>-1.064005</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>-0.073796</td>\n",
       "      <td>0.273126</td>\n",
       "      <td>0.394037</td>\n",
       "      <td>1.217203</td>\n",
       "      <td>-0.783643</td>\n",
       "      <td>1.011596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687227</td>\n",
       "      <td>-0.272977</td>\n",
       "      <td>0.078848</td>\n",
       "      <td>-0.012480</td>\n",
       "      <td>-1.249612</td>\n",
       "      <td>1.758417</td>\n",
       "      <td>-0.389830</td>\n",
       "      <td>2.174819</td>\n",
       "      <td>-0.597049</td>\n",
       "      <td>lmf_ndcg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_id         1         2         3         4         5         6  \\\n",
       "0         7648 -0.431028  0.273519  0.000467 -0.021366  0.411798  0.445795   \n",
       "2        13315 -0.706174 -0.031290 -0.005091 -0.097111  0.111871  0.484369   \n",
       "3        16144  0.672244 -0.958536 -0.005133 -0.093083  0.118219 -0.325690   \n",
       "4        18064 -0.813108  0.897909 -0.105261  0.080410  0.099298 -1.109625   \n",
       "5        24397  0.891482 -1.064005  0.014642 -0.073796  0.273126  0.394037   \n",
       "\n",
       "          7         8         9  ...       192       193       194       195  \\\n",
       "0  1.206461  0.437548 -0.670044  ...  1.261934  0.238986  0.150137 -0.024725   \n",
       "2  0.737223 -1.132764  1.119018  ...  1.040254 -1.375516 -0.064951  0.030435   \n",
       "3  1.434977  0.006304 -0.780396  ...  1.159395 -0.746610  0.042197  0.038217   \n",
       "4  2.775797  0.139941 -0.745728  ...  0.584199  0.619601  0.027197  0.051431   \n",
       "5  1.217203 -0.783643  1.011596  ...  0.687227 -0.272977  0.078848 -0.012480   \n",
       "\n",
       "        196       197       198       199       200        first_place  \n",
       "0 -0.349221  3.509393 -0.146421  1.508804 -0.859744           als_ndcg  \n",
       "2  0.757224  0.444452  0.753969 -0.582505  0.761838           bpr_ndcg  \n",
       "3 -0.813577  1.753534 -0.063353 -0.829087 -1.122440  most_popular_ndcg  \n",
       "4 -1.668557  1.609979 -1.117613  1.222671 -2.145877           lmf_ndcg  \n",
       "5 -1.249612  1.758417 -0.389830  2.174819 -0.597049           lmf_ndcg  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data using pandas\n",
    "metadataset = pd.read_csv(os.path.join(PARSE_DATA_DIR, file ))\n",
    "metadataset = metadataset[metadataset.first_place != 'zeroes']\n",
    "metadataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#als:0\n",
    "#bpr:1\n",
    "#lmf:2\n",
    "#most_pop_3\n",
    "#zeros:4\n",
    "target_pre = metadataset['first_place'].values \n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(target_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalize:\n",
    "  #---- SET INPUTS -----\n",
    "  scaler = StandardScaler()\n",
    "  #Compute the mean and std to be used for later scaling.\n",
    "  scaler.fit(metadataset.drop(columns=['first_place','original_id']))\n",
    "  # Perform standardization by centering and scaling\n",
    "  inputs_transform = scaler.transform(metadataset.drop(columns=['first_place','original_id']))\n",
    "  inputs = pd.DataFrame(inputs_transform)\n",
    "  inputs.head()\n",
    "else:\n",
    "  inputs = metadataset.drop(columns=['first_place','original_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits()\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': 0.1,\n",
    "    'gamma': 1,\n",
    "    'kernel': 'rbf'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_smote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1 \n",
    "reports = []\n",
    "for train_index, test_index in kf.split(inputs):\n",
    "    print('iteration: ', i)\n",
    "    #get data fold\n",
    "    X_train, X_test = inputs.iloc[train_index], inputs.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    #start model \n",
    "    print('fit')\n",
    "    svm.SVC()\n",
    "    clf = svm.SVC(\n",
    "        kernel='linear',\n",
    "        C=params['C'],\n",
    "        gamma=params['gamma'],\n",
    "        kerner=params['kernel'],\n",
    "        verbose=True) # Linear Kernel\n",
    "    \n",
    "    if is_smote:\n",
    "        print('dataset shape %s' % Counter(y_train))\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train_re, y_train_re = sm.fit_resample(X_train, y_train)\n",
    "        print('Resampled dataset shape %s' % Counter(y_train_re))\n",
    "\n",
    "        clf.fit(X_train_re, y_train_re)\n",
    "        print('predict')\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, \n",
    "                               y_pred, \n",
    "                               target_names=np.unique(metadataset['first_place'].values),\n",
    "                              output_dict=True)\n",
    "    reports.append(report)\n",
    "    print('end: ', i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reports = report_average(reports)\n",
    "print_report(avg_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_report(avg_reports):\n",
    "    from prettytable import PrettyTable\n",
    "    x = PrettyTable()\n",
    "\n",
    "    x.field_names = [\"Algorithm\", \"Precision\", \"Recall\", \"F1\"]\n",
    "\n",
    "    for label in avg_reports.keys():\n",
    "        if label in 'accuracy':\n",
    "            x.add_row(['---','---','---','---'])\n",
    "            continue\n",
    "        x.add_row([label, \n",
    "                   avg_reports[label]['precision'], \n",
    "                   avg_reports[label]['recall'], \n",
    "                   avg_reports[label]['f1-score']])\n",
    "\n",
    "\n",
    "    print(x)\n",
    "    print('Accuracy: ', avg_reports['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def report_average(reports):\n",
    "    mean_dict = dict()\n",
    "    for label in reports[0].keys():\n",
    "        dictionary = dict()\n",
    "\n",
    "        if label in 'accuracy':\n",
    "            mean_dict[label] = sum(d[label] for d in reports) / len(reports)\n",
    "            continue\n",
    "\n",
    "        for key in reports[0][label].keys():\n",
    "            dictionary[key] = sum(d[label][key] for d in reports) / len(reports)\n",
    "        mean_dict[label] = dictionary\n",
    "\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 500],  \n",
    "              'gamma': [1, 0.1, 0.01], \n",
    "              'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 532.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 978.6min\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(svm.SVC(), param_grid, cv=2, verbose = 10, n_jobs=-1) \n",
    "grid.fit(inputs, target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
