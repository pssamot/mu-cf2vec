{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_vae = True\n",
    "# Just choose the name of the dataset directory\n",
    "DATA_DIR = '/Users/tomas/Documents/FEUP/Tese/data/ml-20m/processed_70_10_20'\n",
    "if is_vae:\n",
    "    PARSE_DATA_DIR = os.path.join(DATA_DIR, 'embeddings/vae')\n",
    "    file = 'metadataset_k_20.csv'\n",
    "else:\n",
    "    PARSE_DATA_DIR = os.path.join(DATA_DIR, 'embeddings/cdae')\n",
    "    file = '200_fac_metadataset_k_20.csv'\n",
    "    #file = 'metadataset_k_20.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>first_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7648</td>\n",
       "      <td>-0.431028</td>\n",
       "      <td>0.273519</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.021366</td>\n",
       "      <td>0.411798</td>\n",
       "      <td>0.445795</td>\n",
       "      <td>1.206461</td>\n",
       "      <td>0.437548</td>\n",
       "      <td>-0.670044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.261934</td>\n",
       "      <td>0.238986</td>\n",
       "      <td>0.150137</td>\n",
       "      <td>-0.024725</td>\n",
       "      <td>-0.349221</td>\n",
       "      <td>3.509393</td>\n",
       "      <td>-0.146421</td>\n",
       "      <td>1.508804</td>\n",
       "      <td>-0.859744</td>\n",
       "      <td>als_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10208</td>\n",
       "      <td>0.351687</td>\n",
       "      <td>-0.626017</td>\n",
       "      <td>0.034143</td>\n",
       "      <td>-0.080265</td>\n",
       "      <td>0.101129</td>\n",
       "      <td>-0.229498</td>\n",
       "      <td>0.261393</td>\n",
       "      <td>-1.189405</td>\n",
       "      <td>-0.451783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964082</td>\n",
       "      <td>0.825656</td>\n",
       "      <td>0.064932</td>\n",
       "      <td>0.042978</td>\n",
       "      <td>-1.043557</td>\n",
       "      <td>0.562128</td>\n",
       "      <td>0.234560</td>\n",
       "      <td>0.813003</td>\n",
       "      <td>0.511105</td>\n",
       "      <td>zeroes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13315</td>\n",
       "      <td>-0.706174</td>\n",
       "      <td>-0.031290</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>-0.097111</td>\n",
       "      <td>0.111871</td>\n",
       "      <td>0.484369</td>\n",
       "      <td>0.737223</td>\n",
       "      <td>-1.132764</td>\n",
       "      <td>1.119018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040254</td>\n",
       "      <td>-1.375516</td>\n",
       "      <td>-0.064951</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>0.757224</td>\n",
       "      <td>0.444452</td>\n",
       "      <td>0.753969</td>\n",
       "      <td>-0.582505</td>\n",
       "      <td>0.761838</td>\n",
       "      <td>bpr_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16144</td>\n",
       "      <td>0.672244</td>\n",
       "      <td>-0.958536</td>\n",
       "      <td>-0.005133</td>\n",
       "      <td>-0.093083</td>\n",
       "      <td>0.118219</td>\n",
       "      <td>-0.325690</td>\n",
       "      <td>1.434977</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>-0.780396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159395</td>\n",
       "      <td>-0.746610</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>-0.813577</td>\n",
       "      <td>1.753534</td>\n",
       "      <td>-0.063353</td>\n",
       "      <td>-0.829087</td>\n",
       "      <td>-1.122440</td>\n",
       "      <td>most_popular_ndcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18064</td>\n",
       "      <td>-0.813108</td>\n",
       "      <td>0.897909</td>\n",
       "      <td>-0.105261</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>0.099298</td>\n",
       "      <td>-1.109625</td>\n",
       "      <td>2.775797</td>\n",
       "      <td>0.139941</td>\n",
       "      <td>-0.745728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584199</td>\n",
       "      <td>0.619601</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.051431</td>\n",
       "      <td>-1.668557</td>\n",
       "      <td>1.609979</td>\n",
       "      <td>-1.117613</td>\n",
       "      <td>1.222671</td>\n",
       "      <td>-2.145877</td>\n",
       "      <td>lmf_ndcg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_id         1         2         3         4         5         6  \\\n",
       "0         7648 -0.431028  0.273519  0.000467 -0.021366  0.411798  0.445795   \n",
       "1        10208  0.351687 -0.626017  0.034143 -0.080265  0.101129 -0.229498   \n",
       "2        13315 -0.706174 -0.031290 -0.005091 -0.097111  0.111871  0.484369   \n",
       "3        16144  0.672244 -0.958536 -0.005133 -0.093083  0.118219 -0.325690   \n",
       "4        18064 -0.813108  0.897909 -0.105261  0.080410  0.099298 -1.109625   \n",
       "\n",
       "          7         8         9  ...       192       193       194       195  \\\n",
       "0  1.206461  0.437548 -0.670044  ...  1.261934  0.238986  0.150137 -0.024725   \n",
       "1  0.261393 -1.189405 -0.451783  ...  0.964082  0.825656  0.064932  0.042978   \n",
       "2  0.737223 -1.132764  1.119018  ...  1.040254 -1.375516 -0.064951  0.030435   \n",
       "3  1.434977  0.006304 -0.780396  ...  1.159395 -0.746610  0.042197  0.038217   \n",
       "4  2.775797  0.139941 -0.745728  ...  0.584199  0.619601  0.027197  0.051431   \n",
       "\n",
       "        196       197       198       199       200        first_place  \n",
       "0 -0.349221  3.509393 -0.146421  1.508804 -0.859744           als_ndcg  \n",
       "1 -1.043557  0.562128  0.234560  0.813003  0.511105             zeroes  \n",
       "2  0.757224  0.444452  0.753969 -0.582505  0.761838           bpr_ndcg  \n",
       "3 -0.813577  1.753534 -0.063353 -0.829087 -1.122440  most_popular_ndcg  \n",
       "4 -1.668557  1.609979 -1.117613  1.222671 -2.145877           lmf_ndcg  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data using pandas\n",
    "metadataset = pd.read_csv(os.path.join(PARSE_DATA_DIR, file ))\n",
    "#metadataset = metadataset[metadataset.first_place != 'zeroes']\n",
    "metadataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#als:0\n",
    "#bpr:1\n",
    "#lmf:2\n",
    "#most_pop_3\n",
    "#zeros:4\n",
    "target_pre = metadataset['first_place'].values \n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(target_pre)\n",
    "\n",
    "keys = label_encoder.classes_\n",
    "values = label_encoder.transform(keys)\n",
    "labels = dict(zip(values,keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalize:\n",
    "  #---- SET INPUTS -----\n",
    "  scaler = StandardScaler()\n",
    "  #Compute the mean and std to be used for later scaling.\n",
    "  scaler.fit(metadataset.drop(columns=['first_place','original_id']))\n",
    "  # Perform standardization by centering and scaling\n",
    "  inputs_transform = scaler.transform(metadataset.drop(columns=['first_place','original_id']))\n",
    "  inputs = pd.DataFrame(inputs_transform)\n",
    "  inputs.head()\n",
    "else:\n",
    "  inputs = metadataset.drop(columns=['first_place','original_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits()\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_smote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={'C': 316.22776601683796, 'penalty': 'l2', 'solver': 'lbfgs','random_state':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  1\n",
      "fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-9cb481e69837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m#print(y_test[:, 0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 776\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "i = 1 \n",
    "bases = []\n",
    "reports = []\n",
    "base_impact_with_zeroes = []\n",
    "base_impact_without_zeroes_most = []\n",
    "base_impact_without_zeroes_best = []\n",
    "matrix = []\n",
    "\n",
    "base_impact_with_zeroes_without_true_zeroes = []\n",
    "base_impact_without_zeroes_most_without_true_zeroes = []\n",
    "base_impact_without_zeroes_best_without_true_zeroes = []\n",
    "\n",
    "confusion_without_true_zeroes = []\n",
    "reports_without_true_zeroes = []\n",
    "n_classes = len(np.unique(metadataset['first_place'].values))\n",
    "for train_index, test_index in kf.split(inputs):\n",
    "    print('iteration: ', i)\n",
    "    #get data fold\n",
    "    X_train, X_test = inputs.iloc[train_index], inputs.iloc[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    #start model \n",
    "    print('fit')\n",
    "    clf = LogisticRegression(\n",
    "        penalty=params['penalty'], \n",
    "        C=params['C'],\n",
    "        solver=params['solver'],\n",
    "        random_state=params['random_state'],\n",
    "        verbose=5,\n",
    "        n_jobs=4)\n",
    "    \n",
    "    if is_smote:\n",
    "        print('dataset shape %s' % Counter(y_train))\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train_re, y_train_re = sm.fit_resample(X_train, y_train)\n",
    "        print('Resampled dataset shape %s' % Counter(y_train_re))\n",
    "\n",
    "        clf.fit(X_train_re, y_train_re)\n",
    "        print('predict')\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    y_score = clf.decision_function(X_test)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    #print(y_test[:, 0])\n",
    "    for i in range(n_classes):\n",
    "        test = np.where(y_test == i, 1, 0)\n",
    "        print(roc_curve(test, y_score[:, i]))\n",
    "        fpr[i], tpr[i], _ = roc_curve(test, y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    print_roc(fpr, tpr, roc_auc)\n",
    "    \n",
    "    #Remove users that are zeroes \n",
    "    data = {'real':  y_test,\n",
    "        'pred': y_pred,\n",
    "        'original_id':metadataset.iloc[test_index]['original_id'].values\n",
    "    }\n",
    "    df = pd.DataFrame (data, columns = ['real','pred','original_id'])\n",
    "    df = df[df.real != 4]\n",
    "    \n",
    "    #wihtout zeroes users\n",
    "    c_n_z = confusion_matrix(df.real,df.pred)\n",
    "    r_n_z = classification_report(df.real,\n",
    "                                    df.pred, \n",
    "                                   target_names=np.unique(metadataset['first_place'].values),\n",
    "                                  output_dict=True,\n",
    "                                 zero_division=1)\n",
    "    \n",
    "    bl_zeroes_n_z, bl_no_zeroes_most_n_z, bl_no_zeroes_best_n_z = base_level_eval(df.original_id,\n",
    "             list(label_encoder.inverse_transform(df.pred)))\n",
    "\n",
    "    base_impact_with_zeroes_without_true_zeroes.append(bl_zeroes_n_z)\n",
    "    base_impact_without_zeroes_most_without_true_zeroes.append(bl_no_zeroes_most_n_z)\n",
    "    base_impact_without_zeroes_best_without_true_zeroes.append(bl_no_zeroes_best_n_z)\n",
    "    \n",
    "    confusion_without_true_zeroes.append(c_n_z)\n",
    "    reports_without_true_zeroes.append(r_n_z)\n",
    "    \n",
    "    #BASE LEVEL PERFORMANCE\n",
    "    bl_zeroes, bl_no_zeroes_most, bl_no_zeroes_best = base_level_eval(metadataset.iloc[test_index]['original_id'].values,\n",
    "             list(label_encoder.inverse_transform(y_pred)))\n",
    "\n",
    "    base_impact_with_zeroes.append(bl_zeroes)\n",
    "    base_impact_without_zeroes_most.append(bl_no_zeroes_most)\n",
    "    base_impact_without_zeroes_best.append(bl_no_zeroes_best)\n",
    "    \n",
    "    # ALL\n",
    "    report = classification_report(y_test, \n",
    "                                   y_pred, \n",
    "                                   target_names=np.unique(metadataset['first_place'].values),\n",
    "                                  output_dict=True)\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    matrix.append(confusion)\n",
    "    np.set_printoptions(suppress=True)\n",
    "   \n",
    "    reports.append(report)\n",
    "    print('end: ', i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base level impact zeroes 0.2367079550882988\n",
      "base level impact  whithout zeroes, replaced most_pop 0.2589942317741318\n",
      "base level impact  whithout zeroes, replaced best 0.2976851897159204\n",
      "+-------------------+---------------------+----------------------+---------------------+\n",
      "|     Algorithm     |      Precision      |        Recall        |          F1         |\n",
      "+-------------------+---------------------+----------------------+---------------------+\n",
      "|      als_ndcg     | 0.30118653702023523 |  0.5187436037029902  |  0.3810705055908249 |\n",
      "|      bpr_ndcg     | 0.24799341846496997 | 0.16369488700429585  | 0.19713020302151146 |\n",
      "|      lmf_ndcg     | 0.22260383720425908 | 0.010955594137912927 | 0.02086594721790599 |\n",
      "| most_popular_ndcg |  0.3020246307570151 |  0.3015956444531426  |  0.3017581221723364 |\n",
      "|       zeroes      |  0.3369190493953086 |  0.3755013849651598  | 0.35512206436258853 |\n",
      "|        ---        |         ---         |         ---          |         ---         |\n",
      "|     macro avg     |  0.2821454945683576 | 0.27409822285270025  | 0.25118936847303347 |\n",
      "|    weighted avg   |  0.2849728787497991 | 0.30028440295166914  |  0.2688465293128118 |\n",
      "+-------------------+---------------------+----------------------+---------------------+\n",
      "Accuracy:  0.30028440295166914\n",
      "{0: 'als_ndcg', 1: 'bpr_ndcg', 2: 'lmf_ndcg', 3: 'most_popular_ndcg', 4: 'zeroes'}\n",
      "+-------------------+----------+----------+----------+-------------------+--------+\n",
      "|     algorithm     | als_ndcg | bpr_ndcg | lmf_ndcg | most_popular_ndcg | zeroes |\n",
      "+-------------------+----------+----------+----------+-------------------+--------+\n",
      "|      als_ndcg     |  3549.6  |  792.8   |   55.6   |       1451.4      | 993.6  |\n",
      "|      bpr_ndcg     |  2327.0  |  848.6   |   44.8   |       1121.6      | 843.0  |\n",
      "|      lmf_ndcg     |  1903.4  |  563.4   |   42.2   |       835.8       | 505.6  |\n",
      "| most_popular_ndcg |  2583.6  |  638.4   |   38.2   |       1754.4      | 803.0  |\n",
      "|       zeroes      |  1422.6  |  579.2   |   8.2    |       647.4       | 1598.0 |\n",
      "+-------------------+----------+----------+----------+-------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "print('base level impact zeroes', np.mean(base_impact_with_zeroes))\n",
    "print('base level impact  whithout zeroes, replaced most_pop', np.mean(base_impact_without_zeroes_most))\n",
    "print('base level impact  whithout zeroes, replaced best', np.mean(base_impact_without_zeroes_best))\n",
    "avg_reports = report_average(reports)\n",
    "print_report(avg_reports)\n",
    "print_confusion(np.mean( np.array(matrix),axis=0 ),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base level impact zeroes 0.28313501953878345\n",
      "base level impact  whithout zeroes, replaced most_pop 0.3097929920341931\n",
      "base level impact  whithout zeroes, replaced best 0.3560731228836943\n",
      "+-------------------+---------------------+----------------------+----------------------+\n",
      "|     Algorithm     |      Precision      |        Recall        |          F1          |\n",
      "+-------------------+---------------------+----------------------+----------------------+\n",
      "|      als_ndcg     |  0.3425307801833555 |  0.5187436037029902  |  0.4125728441388679  |\n",
      "|      bpr_ndcg     |  0.2984346532200298 | 0.16369488700429585  | 0.21134667162601986  |\n",
      "|      lmf_ndcg     |  0.2325989160211713 | 0.010955594137912927 | 0.020910298439181397 |\n",
      "| most_popular_ndcg | 0.33984863951351335 |  0.3015956444531426  | 0.31954025506069017  |\n",
      "|       zeroes      |         0.0         |         1.0          |         0.0          |\n",
      "|        ---        |         ---         |         ---          |         ---          |\n",
      "|     macro avg     |  0.242682597787614  |  0.3989979458596683  |  0.1928740138529519  |\n",
      "|    weighted avg   | 0.31179346585288326 |  0.2855243992493857  |  0.2700265830545375  |\n",
      "+-------------------+---------------------+----------------------+----------------------+\n",
      "Accuracy:  0.2855243992493857\n",
      "{0: 'als_ndcg', 1: 'bpr_ndcg', 2: 'lmf_ndcg', 3: 'most_popular_ndcg', 4: 'zeroes'}\n",
      "+-------------------+----------+----------+----------+-------------------+--------+\n",
      "|     algorithm     | als_ndcg | bpr_ndcg | lmf_ndcg | most_popular_ndcg | zeroes |\n",
      "+-------------------+----------+----------+----------+-------------------+--------+\n",
      "|      als_ndcg     |  3549.6  |  792.8   |   55.6   |       1451.4      | 993.6  |\n",
      "|      bpr_ndcg     |  2327.0  |  848.6   |   44.8   |       1121.6      | 843.0  |\n",
      "|      lmf_ndcg     |  1903.4  |  563.4   |   42.2   |       835.8       | 505.6  |\n",
      "| most_popular_ndcg |  2583.6  |  638.4   |   38.2   |       1754.4      | 803.0  |\n",
      "|       zeroes      |   0.0    |   0.0    |   0.0    |        0.0        |  0.0   |\n",
      "+-------------------+----------+----------+----------+-------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "print('base level impact zeroes', np.mean(base_impact_with_zeroes_without_true_zeroes))\n",
    "print('base level impact  whithout zeroes, replaced most_pop', np.mean(base_impact_without_zeroes_most_without_true_zeroes))\n",
    "print('base level impact  whithout zeroes, replaced best', np.mean(base_impact_without_zeroes_best_without_true_zeroes))\n",
    "\n",
    "avg_reports = report_average(reports_without_true_zeroes)\n",
    "print_report(avg_reports)\n",
    "print_confusion(np.mean( np.array(confusion_without_true_zeroes),axis=0 ),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Prints function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_roc(fpr, tpr, roc_auc):\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_confusion(values, classes):\n",
    "    from prettytable import PrettyTable\n",
    "    x = PrettyTable()\n",
    "    print(classes)\n",
    "\n",
    "    names = []\n",
    "    names.append('algorithm')\n",
    "    names = names + list(classes.values())\n",
    "\n",
    "    x.field_names = names\n",
    "\n",
    "    i = 0\n",
    "    for row in values:\n",
    "        #row = np.array(row)\n",
    "        r = []\n",
    "        r.append(classes[i])\n",
    "        row = r + list(row)\n",
    "        #r.append(classes[i])\n",
    "        #r = r + row\n",
    "        #row = np.insert(row,0,'als')\n",
    "        x.add_row(row)\n",
    "        #r  = np.concatenate(csses[i],row[])\n",
    "        i +=1\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def report_average(reports):\n",
    "    mean_dict = dict()\n",
    "    for label in reports[0].keys():\n",
    "        dictionary = dict()\n",
    "\n",
    "        if label in 'accuracy':\n",
    "            mean_dict[label] = sum(d[label] for d in reports) / len(reports)\n",
    "            continue\n",
    "\n",
    "        for key in reports[0][label].keys():\n",
    "            dictionary[key] = sum(d[label][key] for d in reports) / len(reports)\n",
    "        mean_dict[label] = dictionary\n",
    "\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_report(avg_reports):\n",
    "    from prettytable import PrettyTable\n",
    "    x = PrettyTable()\n",
    "\n",
    "    x.field_names = [\"Algorithm\", \"Precision\", \"Recall\", \"F1\"]\n",
    "\n",
    "    for label in avg_reports.keys():\n",
    "        if label in 'accuracy':\n",
    "            x.add_row(['---','---','---','---'])\n",
    "            continue\n",
    "        x.add_row([label, \n",
    "                   avg_reports[label]['precision'], \n",
    "                   avg_reports[label]['recall'], \n",
    "                   avg_reports[label]['f1-score']])\n",
    "\n",
    "\n",
    "    print(x)\n",
    "    print('Accuracy: ', avg_reports['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def base_level_eval(users, predictions):\n",
    "    \"\"\"Uses the predctions to return the average of the ndcg impact at base level.\n",
    "    Args:\n",
    "        users: list of users ids\n",
    "        predictions:predictions for users. PREDS HAVE TO be the same index ahas the users list\n",
    "    Returns:\n",
    "        average of ndcg\n",
    "    \"\"\"\n",
    "    print('starting base_level_eval')\n",
    "    results_algo = pd.read_csv(os.path.join(DATA_DIR, 'results_metadataset.csv'))\n",
    "    base_impact = []\n",
    "    base_impact_zeroes_most = []\n",
    "    base_impact_zeroes_best = []\n",
    "    for user_uid, pred in zip(users, predictions):\n",
    "\n",
    "\n",
    "        val = results_algo.loc[ results_algo['original_id'] == user_uid, pred ]\n",
    "        if pred == 'zeroes':\n",
    "            val_zeroes = results_algo.loc[ results_algo['original_id'] == user_uid, 'most_popular_ndcg']\n",
    "            best = results_algo.loc[ results_algo['original_id'] == user_uid]\n",
    "\n",
    "            base_impact.append(val.values[0])\n",
    "            base_impact_zeroes_most.append(val_zeroes.values[0])\n",
    "            base_impact_zeroes_best.append(best.drop('original_id', 1).max(axis=1).values[0])\n",
    "        else:\n",
    "            base_impact.append(val.values[0])\n",
    "            base_impact_zeroes_most.append(val.values[0])\n",
    "            base_impact_zeroes_best.append(val.values[0])\n",
    "\n",
    "\n",
    "        if len(val.values) > 1:\n",
    "            raise Exception(\"More than one case\")\n",
    "\n",
    "    return np.mean(base_impact), np.mean(base_impact_zeroes_most), np.mean(base_impact_zeroes_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 54.0min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 70.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 86.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 95.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 121.0min\n",
      "/usr/local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 141.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 170.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 207.0min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 232.4min finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-05, 1.77827941e-04, 3.16227766e-03, 5.62341325e-02,\n",
       "       1.00000000e+00, 1.77827941e+01, 3.16227766e+02, 5.62341325e+03,\n",
       "       1.00000000e+05]),\n",
       "                         'penalty': ['l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid={\n",
    "    \"C\":np.logspace(-5,5,9), \n",
    "    \"penalty\":[\"l2\"],\n",
    "    \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "}# l1 lasso l2 ridge\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=5, verbose=10, n_jobs=-1)\n",
    "logreg_cv.fit(inputs,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       " 'penalty': ['l2'],\n",
       " 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
